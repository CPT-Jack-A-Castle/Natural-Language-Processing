{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import sys, re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\", \"news-corpus-500k.txt\", \"questions.txt\"]\n",
    "context = []\n",
    "word_context = []\n",
    "with open(sys.argv[1], \"r\") as fh:\n",
    "    for line in fh:\n",
    "        words = [\"<s>\"]+[w for w in line.split(\" \") if re.search('\\w', w)]+[\"</s>\"]\n",
    "        context += words\n",
    "        word_context += [\" \".join([words[i+j] for j in range(2)]) for i in range(len(words)-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['set', 'It', 'can', 'involve', 'thousands', 'tonnes', 'construction', 'waste', 'cost', 'millions', 'pounds', 'clear', 'up', 'Indonesia', 'example', 'are', '17,000', 'madrassas--and', 'local', 'NGO', 'Conservation', 'Religion', 'Initiative', 'reports', 'good', 'progress', 'persuading', 'teachers', 'those', 'schools', 'preach', 'practise', 'stewardship', 'NEW', 'YORK', 'AP', 'Pfizer', 'Inc', 'world', 'biggest', 'drug', 'maker', 'revenue', 'focus', 'recent', 'deals', 'new', 'research', 'data', 'integration', 'Wyeth', 'which', 'it', 'bought', 'year', 'ago', 'third-quarter', 'results', 'before', 'stock', 'market', 'opens', 'As', 'East', 'I', 'jumped', 'four', 'hearts', 'preempt', 'South', 'had', '0-1-6-6', 'distribution', 'wouldn', \"'t\", 'shut', 'Even', 'though', 'were', 'both', 'made', 'activists', 'stake', 'battle', 'between', 'protesters', 'police', 'do', 'seem', 'show', 'tactics', 'escalating', 'tensions', 'another', 'part', 'city', 'Obama', 'has', 'proposed', 'subsidies']\n"
     ]
    }
   ],
   "source": [
    "print(list(context)[300:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context = Counter(context)\n",
    "word_context = Counter(word_context)\n",
    "\n",
    "total_words = sum(list(context.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249860 3040651\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(value):\n",
    "    return context[value]/total_words\n",
    "\t#return context.get(value, 0)/total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(unigram(\"through\") > unigram(\"threw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram(value, smoothing=0):\n",
    "    try:\n",
    "        return (word_context.get(value, 0)+smoothing)/(context.get(value.split(\" \")[0], 0)+smoothing*(len(context)))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001366120218579235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram(\"check she\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(p1, p2, a1, a2):\n",
    "    if p1 > p2:\n",
    "        return a1, p1, False\n",
    "    elif p1 < p2:\n",
    "        return a2, p2, False\n",
    "    else:\n",
    "        return a1, p2, True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('through', 0.0006337913624159014, False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(unigram(\"through\"), unigram(\"threw\"), \"through\", \"threw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram model: whether\n",
      "Bigram model: whether\n",
      "Bigram with add-1 smoothing model : whether\n",
      "\n",
      " \n",
      "Unigram model: through\n",
      "Bigram model: through\n",
      "Bigram with add-1 smoothing model : through\n",
      "\n",
      " \n",
      "Unigram model: peace\n",
      "Bigram model: piece\n",
      "Bigram with add-1 smoothing model : piece\n",
      "\n",
      " \n",
      "Unigram model: court\n",
      "Bigram model: court\n",
      "Bigram with add-1 smoothing model : court\n",
      "\n",
      " \n",
      "Unigram model: allowed\n",
      "Bigram model: allowed\n",
      "Bigram with add-1 smoothing model : allowed\n",
      "\n",
      " \n",
      "Unigram model: check\n",
      "Bigram model: check\n",
      "Bigram with add-1 smoothing model : check\n",
      "\n",
      " \n",
      "Unigram model: here\n",
      "Bigram model: hear\n",
      "Bigram with add-1 smoothing model : hear\n",
      "\n",
      " \n",
      "Unigram model: serial\n",
      "Bigram model: Incorrect Answer\n",
      "Bigram with add-1 smoothing model : cereal\n",
      "\n",
      " \n",
      "Unigram model: choose\n",
      "Bigram model: Incorrect Answer\n",
      "Bigram with add-1 smoothing model : choose\n",
      "\n",
      " \n",
      "Unigram model: Incorrect Answer\n",
      "Bigram model: Incorrect Answer\n",
      "Bigram with add-1 smoothing model : sell\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "ra = [\"whether\", \"through\", \"piece\", \"court\", \"allowed\", \"check\", \"hear\", \"cereal\", \"chews\", \"sell\"]\n",
    "ai, ca_u, ca_b, ca_ba = 0, 0, 0, 0\n",
    "with open(sys.argv[2], \"r\") as fh:\n",
    "    for line in fh:\n",
    "        u1, u2, b1, b2, ba1, ba2 = 1, 1, 1, 1, 1, 1\n",
    "        answer1, answer2 = line.split(\":\")[1].split(\"/\")[0].strip(), line.split(\":\")[1].split(\"/\")[1].strip()\n",
    "        line = line.split(\":\")[0]\n",
    "        words = [\"<s>\"]+[w for w in line.split(\" \") if re.search('\\w', w)]+[\"</s>\"]\n",
    "        bi_words = [\" \".join([words[i+j] for j in range(2)]) for i in range(len(words)-1)]\n",
    "\n",
    "        for word in words:\n",
    "            u1 *= unigram(word.replace(\"____\", answer1))\n",
    "            u2 *= unigram(word.replace(\"____\", answer2))\n",
    "\n",
    "        for bi_word in bi_words:\n",
    "            b1 *= bigram(bi_word.replace(\"____\", answer1))\n",
    "            b2 *= bigram(bi_word.replace(\"____\", answer2))\n",
    "\n",
    "            ba1 *= bigram(bi_word.replace(\"____\", answer1), 1)\n",
    "            ba2 *= bigram(bi_word.replace(\"____\", answer2), 1)\n",
    "\n",
    "        print(\"Unigram model: \", end=\"\")\n",
    "        ans, prob, tie = predict(u1, u2, answer1, answer2)\n",
    "        if tie == True:\n",
    "            if prob == 0: print(\"Incorrect Answer\")\n",
    "            else: \n",
    "                ca_u += 0.5\n",
    "                print(ans)\n",
    "        else:\n",
    "            if ans == ra[ai]: ca_u += 1\n",
    "            print(ans)\n",
    "\n",
    "        print(\"Bigram model: \", end=\"\")\n",
    "        ans, prob, tie = predict(b1, b2, answer1, answer2)\n",
    "        if tie == True:\n",
    "            if prob == 0: print(\"Incorrect Answer\")\n",
    "            else: \n",
    "                ca_b += 0.5\n",
    "                print(ans)\n",
    "        else:\n",
    "            if ans == ra[ai]: ca_b += 1\n",
    "            print(ans)\n",
    "\n",
    "\n",
    "        print(\"Bigram with add-1 smoothing model : \", end = \"\")\n",
    "        ans, prob, tie = predict(ba1, ba2, answer1, answer2)\n",
    "        if tie == True:\n",
    "            if prob == 0: print(\"Incorrect Answer\")\n",
    "            else: \n",
    "                ca_ba += 0.5\n",
    "                print(ans)\n",
    "        else:\n",
    "            if ans == ra[ai]: ca_ba += 1\n",
    "            print(ans)\n",
    "\n",
    "        ai+=1\n",
    "\n",
    "        print(\"\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram percentage accuracy:  50.0\n",
      "Bigram percentage accuracy:  70.0\n",
      "Bigram with add-1 smoothing percentage accuracy:  90.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram percentage accuracy: \", (ca_u/len(ra)) * 100)\n",
    "print(\"Bigram percentage accuracy: \", (ca_b/len(ra)) * 100)\n",
    "print(\"Bigram with add-1 smoothing percentage accuracy: \", (ca_ba/len(ra)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
